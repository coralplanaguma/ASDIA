---
title: "ASDIA Projet 1"
output:
  html_document:
    df_print: paged
---



# Partie 1 : Apprentissage supervisé pour la classification 

L'objet de cette partie est de démontrer le résultat suivant.

**Théorème.** *Soit $q({\bf x})$ une fonction arbitraire à valeur dans $[0,1]$ et* 
$$
q_{\rm opt}({\bf x}) = p(y = 1|{\bf x}) \, , \quad \forall {\bf x}.
$$
*Alors, nous avons*
$$
\mathbb{E}[L(q({\bf x}), y )] \geq \mathbb{E}[L(q_{\rm opt}({\bf x}), y )] .
$$

*  **Conditionnement** : 

$$
\mathbb{E}[L(q({\bf x}), y)]=\int\mathbb{E}[L(q({\bf x}), y)| x]p({\bf x})dx
$$
Comme $p({\bf x }) \in [0, 1] (>0)$, pour minimiser l'espérance $\mathbb{E}[L(q({\bf x}), y )]$ il suffit de minimiser l'espérance conditionnelle $\mathbb{E}[L(q({\bf x}), y ) | {\bf x}]$ pour tout ${\bf x}$.

*  **Entropie croisée** :

$$
\begin{align}
\mathbb{KL}(p \| p^\prime) &= p(y = 0) \log \frac{p(y = 0)}{p \prime y = 0} + p(y =1) \log \frac{p(y=1)}{p \prime (y = 1)}\\
&= h(p, p\prime) + p(y=0)\log p(y=0) + p(y=1) \log p(y=1)\\
&= h(p, p \prime) - h(p)
\end{align}
$$

Comme la divergence de Kulback-Leibler est positive, on obtient bien l'inégalité suivante : 
$$
h(p, p') \geq h(p)
$$


* **Entropie croisée et log-loss ** : On appelle $q_{.}({\bf x})$ la loi de Bernoulli de paramètre $q({\bf x})$. Démontrer que 

$$
\mathbb{E}[L(q({\bf x}), y ) | {\bf x}]  = h(p_{\sf Y}(.|{\bf x}), q_{.}({\bf x}))  .  
$$


* Démontrer le théorème. 


En conclusion, minimiser l'espérance conditionnelle $\mathbb{E}[L(q({\bf x}), y) | {\bf x} ]$ revient à minimiser la divergence $D_{KL}(  p_{\sf y|{\bf x}} \| q({\bf x}) )$. Ainsi, nous pouvons affirmer que minimiser la perte moyenne log-loss revient à minimiser l'information perdue lorsque l'on approche la loi cible $p(y|{\bf x})$ par un modèle probabiliste $q({\bf x})$. 


* On suppose que la perte moyenne est évaluée à partir d'un échantillon de données d'apprentissage $({\bf x}_i, y_i)$, $i = 1, \dots, n$, indépendantes et de même loi. On suppose que la loi conditionnelle est modélisée à l'aide d'ensemble de paramètres, $\theta$, par la fonction suivante

$$
p(y = 1 | {\bf x}, \theta) = q({\bf x}, \theta) \, .
$$
Démontrer que le minimum de la fonction de perte correspond au maximum de la vraisemblance pour ce modèle. 


# Partie 2 : Reconnaissance de chiffres manuscrits (2 et 7)

## Lecture des données

* Lire les données MNIST. Il y a 4 ensembles de variables. 
```{r}
  library(keras)
  library(magrittr)
  mnist <- dataset_mnist()
  x_train <- mnist$train$x
  y_train <- mnist$train$y
  x_test <- mnist$test$x
  y_test <- mnist$test$y
```

* Filtrer les données correspondant aux chiffres $2$ et $7$. Commenter et compléter le code suivant. Exécuter le code en changeant l'option de chunck. 


```{r}
# On conserve les 2 et les 7 uniquement
  boo_train <- y_train == 2 | y_train == 7 
  x_train <- mnist$train$x[boo_train,,]
  y_train <- mnist$train$y[boo_train]

# Idem pour le set de test
  boo_test <- y_test == 2 | y_test == 7
  x_test <- mnist$test$x[boo_test,,]
  y_test <- mnist$test$y[boo_test]
```


* Utiliser la fonction `image()` pour visualiser le premier chiffre test de la base de données réduite. C'est un 7. 

```{r}
  image(t(x_test[1, 28:1,]), col = grey.colors(5))
```


* Les images de dimension 28x28 doivent être converties en vecteurs de longueur 784 ($= 28 \times 28$). Cela peut se faire de plusieurs manières. En particulier, la fonction `array_reshape()` de keras est très utile pour cela.  


```{r}
# reshape
  x_train <- array_reshape(x_train, c(nrow(x_train), 784))
  x_test <- array_reshape(x_test, c(nrow(x_test), 784))
```

* Normaliser les données pour obtenir des valeurs réelles (flottants) entre 0 et 1 en divisant les valeurs présentes par 255.  Utiliser la fonction `image()` pour visualiser le premier chiffre test de la base de données réduite dans cette nouvelle représentation. 


```{r}
# rescale
  x_train <- x_train/255
  x_test <- x_test/255

# le symbol %>% est similaire au 'pipe' d'unix (library(magrittr))
  dim(x_test)
  x_test[1,] %>% matrix(nrow = 28) %>% .[,28:1] %>% image(col = grey.colors(5))
```


* Les données de classe sont des entiers 2,7. Convertir ces données en variables booléennes ou binaires. La valeur 1 ou `TRUE` correspondra à un 7.
  
```{r}
  y_train <- y_train == 7
  y_test <-  y_test == 7
```


## Ajuster un réseau de neurone avec keras

* Construire un réseau de neurones à deux couches cachées à l'aide de la fonction `keras_model_sequential()`, en faisant varier les paramètres des couches comme ci-dessous. Définir les termes apparaissant dans la construction du modèle.


* Commenter et compléter le code suivant.  

```{r}
  model <- keras_model_sequential() 
  model %>% 
    # Initialisation de la première couche avec fonctoin d'activation "relu" et 256 neurones.
    layer_dense(units = 256, activation = 'relu', input_shape = 784) %>% 
    # On associe aléatoirement la valeur 0 à 50% des imahes d'entrée pour éviter l'over fitting.
    layer_dropout(rate = 0.5) %>% 
    # Initialisation de la deuxième couche avec 128 neurones.
    layer_dense(units = 128, activation = 'relu') %>%
    layer_dropout(rate = 0.5) %>%
    # Initialisation de dernière couche
    layer_dense(units = 1, activation = 'sigmoid')
```

* Donner un tableau de correspondance entre les notions mathématiques introduites dans la section précédente et les termes apparaissant dans la construction du modèle. 

```{r}
terme <- c("units = 256", "input_shape")
definition <- c("Dimension de la première couche cachée (W_2)", "Dimension des observations")
data.frame(terme, definition)
```


* Compiler le modèle en précisant la fonction de perte (binary) et demander de visualiser le taux de bonne classification (accuracy). Le choix de l'optimiseur est spécifié. 


```{r}
# Configuration du modèle pour l'entraînement  
  model %>% compile(
    loss = 'binary_crossentropy',
    optimizer = optimizer_rmsprop(lr = 0.001, rho = 0.9, decay = 0),
    metrics = c('accuracy')
)
```

* Donner un tableau de correspondance entre les notions mathématiques introduites dans la section précédente et les termes apparaissant dans la compilation du modèle. 

```{r}
terme <- c("loss", "optimizer", "lr", "rho", "decay", "accuracy")
definition <- c("Fonction de perte","Méthode de gradient stochastique","Taux d'apprentissage (pas dans la descente de gradient)","Facteur de décroissance moyenne du gradient","Baisse du taux d'apprentissage à chaque itération","Précision utilisée pour mesurer la pertinence du modèle")
data.frame(terme, definition)
```



* Allons-y Alonso, pour ajuster le réseau (apprentissage)

```{r}
# A pprentissage : on entraîne le modèle
  history <- model %>% fit(
                        x_train, 
                        y_train, 
                        epochs = 20, 
                        batch_size = 128, 
                        validation_data = list(x_test, y_test)
)
```

* Donner un tableau de correspondance entre les notions mathématiques introduites dans la section précédente et les termes apparaissant dans l'apprentissage du modèle. 
```{r}
terme <- c("x_train", "y_train", "epochs", "batch_size", "validation_data")
definition <- c("Ensemble des images (observations)","Sortie attendue","Nombre d'entraînements du modèle", "Nombre d'images utilisées par le réseau à chaque itération", "Données permettant d'évaluer le modèle")
data.frame(terme, definition)
```
* Quelle est signification des courbes `loss` et `val_loss` que l'on voit tracées? 

```{r}
plot(history)
```
Les coubes "loss" et "val_loss" représentent respectivement les pertes du modèle pour les données d'entraînement (x_train, y_train) et pour les données de tests (x_test, y_test).

* Evaluer le modèle sur les données de test (erreur de classification et perte log loss)


```{r}
model %>% evaluate(x_test, y_test)
```


* Donner une matrice de confusion pour les classements effectués par le modèle sur le jeu test

```{r}
# help(table)
pred_class <- model %>% predict_classes(x_test)
table(predicted = pred_class, observed = mnist$test$y[boo_test])
```

* Montrer deux chiffres manuscrits que la machine n'a pas réussi à classer correctement. Donner la liste des mal classés et les probabilités de classement pour chacune des erreurs.

```{r}
index = 1:2060
wrong = index[pred_class[, 1]!=y_test]

x_test[145,] %>% matrix(nrow = 28) %>% .[,28:1] %>% image(col = grey.colors(5))
x_test[223,] %>% matrix(nrow = 28) %>% .[,28:1] %>% image(col = grey.colors(5))


predict_proba(model, x_test)[145]
predict_proba(model, x_test)[223]

```


## Défi MNIST 

Pour les données de l'exercice précédent, répondre aux questions suivantes.
  
  
  Construisons 6 modèles dont nous feons varier les paramètres de la anière suivante:
  - nombre de couches cachées : 1 ou 5, 
  - nombre de neurones par couche cachée : 10 ou 100, 
  - valeur de `dropout` par couche cachée : 0.2 ou 0.8.
  
```{r}
set.seed(3)
nb_couches <-c(1, 5)
nb_neurones<-c(10, 100)
val_dropout<-c(0.2, 0.8)



create_model = function (nb_couches, nb_neurones, val_dropout){
  #Renvoie un modèle correspondant aux critères entrés en paramètres
  wanted_model <- keras_model_sequential()
  wanted_model %>% 
    # Initialisation de la première couche avec fonction d'activation "relu" et 256 neurones.
    layer_dense(units = nb_neurones, activation = 'relu', input_shape = 784) %>% 
    layer_dropout(rate = val_dropout)
  if(nb_couches != 1){
    for (i in 1:nb_couches){
      wanted_model %>% 
      # Initialisation des couches suivantes
      layer_dense(units = nb_neurones, activation = 'relu') %>% 
      layer_dropout(rate = val_dropout)
    }
  }
  wanted_model %>% 
  # Initialisation de dernière couche
  layer_dense(units = 1, activation = 'sigmoid')
  return (wanted_model);
}


modele_1_10_2 <- create_model(1, 10, 2)
modele_1_10_8 <- create_model(1, 10, 8)
modele_1_100_2 <- create_model(1, 100, 2)
modele_1_100_8 <- create_model(1, 100, 8)
modele_5_10_2 <-  create_model(5, 10, 2)
modele_5_10_8 <-  create_model(5, 10, 8)
modele_5_100_2 <-  create_model(5,100, 2)
modele_5_100_8 <- create_model(5, 100, 8)

res_log_loss<-c()
res_acc<-c()
compteur = 1

model_instructions = function(model1){

      # Configuration du modèle pour l'apprentissage
      model1 %>% compile(
          loss = 'binary_crossentropy',
          optimizer = optimizer_rmsprop(lr = 0.001, rho = 0.9, decay = 0),
          metrics = c('accuracy')
      )
      
      # Entraînement du réseau
      history <- model1 %>% fit(
                              x_train, 
                              y_train, 
                              epochs = 20, 
                              batch_size = 128, 
                              validation_data = list(x_test, y_test))
      
      res <- c()
      res = model1 %>% evaluate(x_test, y_test)
      return(res)

}

res_log_loss[1] = model_instructions(modele_1_10_2)$loss
res_log_loss[2] = model_instructions(modele_1_10_8)$loss
res_log_loss[3] = model_instructions(modele_1_100_2)$loss
res_log_loss[4] = model_instructions(modele_1_100_8)$loss
res_log_loss[5] = model_instructions(modele_5_10_2)$loss
res_log_loss[6] = model_instructions(modele_5_10_8)$loss
res_log_loss[7] = model_instructions(modele_5_100_2)$loss
res_log_loss[8] = model_instructions(modele_5_100_8)$loss
  
res_acc[1] = model_instructions(modele_1_10_2)$acc
res_acc[2] = model_instructions(modele_1_10_8)$acc
res_acc[3] = model_instructions(modele_1_100_2)$acc
res_acc[4] = model_instructions(modele_1_100_8)$acc
res_acc[5] = model_instructions(modele_5_10_2)$acc
res_acc[6] = model_instructions(modele_5_10_8)$acc
res_acc[7] = model_instructions(modele_5_100_2)$acc
res_acc[8] = model_instructions(modele_5_100_8)$acc

names<-c("modele_1_10_2", "modele_1_10_8", "modele_1_100_2", "modele_1_100_8", "modele_5_10_2", "modele_5_10_8", "modele_5_100_2","modele_5_100_8")
data <- data.frame(names, res_log_loss, res_acc)
barplot(res_log_loss, main = "Comparaison des erreurs de logloss", ylab = "logloss", legend.text = data$names, col = rainbow((8)))
barplot(res_acc, main = "Comparaison des erreurs de classification", ylab = "accuracy", ylim = c(0.96, 0.99), legend.text = data$names, args.legend = list(x = "bottomleft"), col = rainbow(8))
```


* Quel modèle de prédiction vous parait être le meilleur ? 

Afin de faire notre choix, on essaie de trouver un modèle qui maximise l'accuracy et qui minimise la valeur du log loss, ainsi on choisi le modèle avec les paramètres 1, 100, 0.2.

* Donner la liste des chiffres mal classés et les probabilités de classement pour chacune des erreurs. 
```{r}
probas<-c()
pred_class <- modele_1_100_2 %>% predict_classes(x_test)
wrong = index[pred_class[, 1]!=y_test]
for (i in 0:length(wrong)){
  probas[i] = predict_proba(modele_1_100_2, x_test)[wrong[i]]
}
data.frame(wrong, probas)
```

# Partie 3 : Analyse de critiques de films (IMDB)



```{r}
library(magrittr)
library(keras)

```

## Index des termes et sacs de mots.


```{r}
  index <- keras::dataset_imdb_word_index()
  names(index[index == 1])
```

Sans surprise, le terme le plus fréquemment utilisé est l'article "the". Sa valeur dans l'index est donc égale à 1. 


```{r}
  # Réordonnons l'index
  o <- as.numeric(index) %>% order()
  index[o[1:10]] %>% names()
```

Nous voyons qu'il s'agit d'articles, de prépositions ou de termes non-informatifs, comme par exemple, des éléments extraits des balises html (br). Il sera peut-être préférable d'éliminer les termes les plus utilisés. L'entrée 49 correspondant au terme "good".

Pour réduire le temps de calcul, nous conservons uniquement les 5000 termes les plus fréquents.

```{r}
  imbd <-  keras::dataset_imdb(path = "imdb.npz",
                              num_words = 5048, # index d dernier terme pris en compte
                              skip_top = 49, # élimination des premiers termes (non pertinents)
                              oov_char = -2, # craractère qui remplace les termes éliminés
                              start_char = -1, # début de séquence
                              index_from = 0)
```


## Défi "analyse de sentiments"

### Lecture des données

* Ecrire une ligne de commande R permettant convertir le document 12 en un vecteur de longueur 5000, indiquant le nombre d'apparition de chacun des indices allant de 1 à 5000 dans ce document.  


```{r}
  # Conversion du document 12 en un vecteur de longueur 5000
  help(sapply)
  doc <- imbd$train$x[[12]]
  result <- sapply(49:5048, FUN = function(x) length(doc[doc == x]))
  result[1:100]
```

* Constituer un jeu de données comportant 10000 documents choisis pour moitié dans l'ensemble "train" et pour moitié dans l'ensemble "test" de l'IMBD. Techniquement nous le constituerons en 20 étapes, pour limiter l'impact sur la mémoire. Commenter et exécuter le code suivant


```{r}
x_imbd <- NULL

  for (i in 1:10){
    
    x_imbd_500 <- NULL
    
      for (j in (500*(i-1)+1):(500*i)){
        
        # on récupère les 5000 premiers documents de imbd$train
        
        doc_temp <- imbd$train$x[[j]]
        x_imbd_500 <- rbind(x_imbd_500, 
                         sapply(49:5048, 
                                FUN = function(ind) sum(doc_temp == ind)))
        
        if (j%%500 == 0) print(j) # ca rassure
    }
    x_imbd <- rbind(x_imbd, x_imbd_500)
  }

 for (i in 1:10){
   
    x_imbd_500 <- NULL
    
      for (j in (500*(i-1)+1):(500*i)){
        
        # On récupère les 5000 premiers documents de x$test
        
        doc_temp <- imbd$test$x[[j]]
        x_imbd_500 <- rbind(x_imbd_500, 
                         sapply(49:5048, 
                                FUN = function(ind) sum(doc_temp == ind)))
        
        if (j%%500 == 0) print(j) # ca rassure
    }
    x_imbd <- rbind(x_imbd, x_imbd_500)
  }
```

* Que contient l'objet `x_imbd` ?
x_imbd contient désormais 10000 documents. Les 5000 premiers appartenaient à l'ensemble "train", les autres à l'ensemble "test". Les documents sont stockés sous la forme de vecteurs de longueurs 5000. A la position d'indice i, on trouve la fréquence d'apparition du terme d'index i dans le document. 

* Définir les classes $y = 0$ ou $y=1$ pour chaque élément de `x_imbd`
```{r}
classe <- c("y=0", "y=1")
definition <- c("opinion positive", "opinion négative")
data.frame(classe, definition)
```


```{r}
# Récupération de s valeurs y associées aux fichiers sélectionnés                                           
  y_imbd <- c(imbd$train$y[1:5000], imbd$test$y[1:5000])
```

Et voilà. On est en pleine forme et on dispose d'une base d'apprentissage comportant les fréquences d'apparition des mots de l'index pour 10000 documents (`x_imbd`) et les opinions des utilisateurs `y_imbd`. Le défi peut vraiment commencer.


#### Etude d'association

Le but d'une étude d'association est d'identifier les termes les plus associés aux opinions positives ou négatives des utilisateurs. Pour cela, nous evaluons la correlation au carré entre l'occurrence de chaque terme et l'opinion de l'utilisateur (présence d'un 1). Il se peut que certaines valeurs de corrélation ne soient pas calculables à cause d'un écart-type nul. 

* Calculer le coefficient de corrélation au carré entre les fréquences d'apparition des termes de l'index et opinion des utilsateurs (5000 valeurs).

```{r}

  # termes
  x <- x_imbd
  
  # opinion
  y <- y_imbd
  
  # comment
  r <- cor(x, y)
  r2 <- r^2

```


* Montrer les termes dont la valeur d'association $r^2$ est supérieure à 3 pour cent (0.02), puis supérieure à 0.02, et à 0.01. _Note_ : Il faut effectuer un décalage de 48 indices dans l'index pour trouver le codage correct.


```{r}
  # quelque chose à changer
  index[o[ which(r2 > 0.03) + 48 ]] %>% names()
  index[o[ which(r2 > 0.02) + 48 ]] %>% names()
  index[o[ which(r2 > 0.01) + 48 ]] %>% names()
```

* Dans quelles proportions les termes de valeur d'association $r^2$ supérieure à 0.02 apparaissent-ils dans les documents ? Représenter graphiquement ces proportions à l'aide d'un diagramme en barre. 


```{r}
# Calculer la frequence des termes realisant la condition
diag_freq = function(corr, color){
  ind <- c()
  list <- index[o[ which(r2 > corr) + 48 ]]
  for (i in 1:length(list)){
    ind[i]=list[[i]]
  }

  freq <- x[,ind] %>% apply(2, mean) #moyenne sur les colonnes
# mots dans l'index et barplot
  names(freq) <-  index[o[which(r2 > corr) + 48]] %>% names() 
  b = barplot(sort(freq, decreasing = TRUE), col = color, las = 2)
  return(freq)
}


diag_freq(0.02, "lightblue")
```



* Dans quelles proportions les termes de valeur d'association $r^2$ supérieure à 0.01 apparaissent-ils dans les documents ? Représenter graphiquement ces proportions  à l'aide d'un diagramme en barre.

```{r}
diag_freq(0.01, "lightblue")
```



* Dans quelles proportions les termes de valeur d'association $r = cor(x,y)$ supérieure à 0.1 apparaissent-ils dans les documents ? Représenter graphiquement ces proportions  à l'aide d'un diagramme en barre.

```{r}
ind <- c()
  list <- index[o[ which(r > 0.1) + 48 ]]
  for (i in 1:length(list)){
    ind[i]=list[[i]]
  }

  freq <- x[,ind] %>% apply(2, mean) #moyenne sur les colonnes
# mots dans l'index et barplot
  names(freq) <-  index[o[which(r > 0.1) + 48]] %>% names() 
  b = barplot(sort(freq, decreasing = TRUE), col = "pink", las = 2)

```



*  Dans quelles proportions les termes de valeur d'association $r$ inférieure à $-0.1$ apparaissent-ils dans les documents ? Représenter graphiquement ces proportions  à l'aide d'un diagramme en barre.


```{r}

ind <- c()
list <- index[o[ which(r < -0.1) + 48 ]]
  for (i in 1:length(list)){
    ind[i]=list[[i]]
  }
  
freq <- x[,ind] %>% apply(2, mean) #moyenne sur les colonnes
# mots dans l'index et barplot
names(freq) <-  index[o[which(r < -0.1) + 48]] %>% names()  
barplot(sort(freq, decreasing = TRUE), col = "palegreen", las = 2)
```



#### Modèles d'apprentissage 


* \`A l'aide des outils de _keras_, ajuster des modèles d'apprentissage aux données contenues dans le défi : "x_imbd" et "y_imbd". Considérer la graine du générateur aléatoire `seed` comme un hyper-paramètre (`set.seed(seed)`).

* Dans un tableau, décrire les performances de 6 méthodes choisies pour des échantillons d'apprentissage et de test que vous aurez créés vous-mêmes à partir des données "x_imbd" et "y_imbd". Les performances seront mesurées par les erreurs de classification et d'entropie croisée (log loss).

* Donner le code R correspondant au meilleur modèle que vous avez ajusté (chunk ci-dessous). On considèrera la graine du générateur aléatoire comme un hyperparamètre supplémentaire du modèle. Donner la valeur finale d'entropie croisée estimée sur votre ensemble test. On fera en sorte que le résulat soit complètement reproductible à partir du code proposé. 


```{r eval = FALSE}
# code de mon meilleur modèle
# Ne pas oublier d'inclure la seed du générateur aléatoire 
# set.seed(seed = 5427381)
  model <-  deus_ex_machina
```




# Règles de rendu

* Ce projet donne lieu à un compte rendu séparé, dans lequel on aura pris soin de reporter les sections de ce document comportant vos réponses, commentaires, et vos codes complétés. Merci de ne pas reporter les sections "théoriques".

* Les codes R doivent être inclus dans le texte du compte-rendu (menu **Insert**) et l'ensemble doit être commenté avec précision. **Les commentaires compteront pour une part importante dans la note**.

* Le compte-rendu doit être déposé **dans TEIDE**. 

* Le compte-rendu doit être déposé **au format HTML uniquement** et intitulé "Rendu_Projet_1.html". Utiliser la fonction **knitr** du menu de rstudio pour obtenir le document au format souhaité. **Les fichiers sources (Rmd ou nb.html) ne seront pas acceptés**.




